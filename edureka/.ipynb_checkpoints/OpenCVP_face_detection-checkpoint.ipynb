{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV tutorial \n",
    "* openCV is a library of python desinged to solve computer vision problems.\n",
    "* it was first devloped in 1999 at intel by Gary Brad Sky and first release in 2000\n",
    "* An openCV python is nothing but it is wrapper of original opencv c++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  read the image\n",
    "img1 = cv2.imread('a.jpg',1) # 1 for color\n",
    "img2 = cv2.imread('a.jpg',0) # 0 for gray scale or balck & white\n",
    "img3 = cv2.imread('a.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method astype of numpy.ndarray object at 0x000001EE77B32B20>\n",
      "uint8\n",
      "(392, 640, 3)\n",
      "752640\n",
      "\n",
      "<built-in method astype of numpy.ndarray object at 0x000001EE77B320D0>\n",
      "uint8\n",
      "(392, 640)\n",
      "250880\n"
     ]
    }
   ],
   "source": [
    "print(img1.astype)\n",
    "print(img1.dtype)\n",
    "print(img1.shape) # extra 3 for RGB  (392, 640, 3)\n",
    "print(img1.size)\n",
    "print()\n",
    "# gray img\n",
    "print(img2.astype)\n",
    "print(img2.dtype)\n",
    "print(img2.shape)\n",
    "print(img2.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image \n",
    "cv2.imshow(\"window_1\",img2) \n",
    "# it take two parameter \n",
    "#    1. for name of the window\n",
    "#    2. for name of image\n",
    "\n",
    "##### waitkey() and destroyAllwindows() are neccaery function otherwise window goes crush \n",
    "\n",
    "# cv2.waitKey(0) # wait until a user presses a key\n",
    "cv2.waitKey(2000) # wait for 2000 milliseconds\n",
    "cv2.destroyAllWindows() # close window based on waitforkey parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resize image using cv2.resize() function\n",
    "resize_img = cv2.resize(img1,(500,500))\n",
    "resize_img = cv2.resize(img1, (int(img1.shape[1]/2), int(img1.shape[0]/2))) # shape give list of size \n",
    "cv2.imshow(\"before\",img1) \n",
    "cv2.imshow(\"afte\",resize_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection \n",
    "\n",
    "step 1. Create a cascade classifier. It will contain the features of the face\n",
    "\n",
    "step 2. OpenCV will read the image and the features file <br>\n",
    "        Search for the row and column values of the face\n",
    "        \n",
    "step 3. Display the img with the reactangular face box        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CascadeClassifier object\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    " # parameter = path of the xml file which contains the face feature\n",
    "\n",
    "#Reading the image\n",
    "img1 = cv2.imread('c.jpg',1)\n",
    "img2 = cv2.imread('c.jpg') \n",
    "\n",
    "#convert to grayscale\n",
    "img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "# both are same so no need to convt into gray scale \n",
    "\n",
    "\n",
    "cv2.imshow(\"a\",img1)\n",
    "cv2.imshow(\"win\",img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# search co-ordinates of imag\n",
    "faces = face_cascade.detectMultiScale(img2,scaleFactor = 1.05,minNeighbors=5)\n",
    "# scalefactor =  decrease the shape value by 5%, until the face is found.\n",
    "# smaller this value, the greater is the accuracy\n",
    "\n",
    "\n",
    "# print(type(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[105  16  41  41]\n",
      " [203  21  43  43]\n",
      " [255  22  38  38]\n",
      " [308  22  38  38]\n",
      " [ 52  17  49  49]\n",
      " [  4  20  43  43]]\n"
     ]
    }
   ],
   "source": [
    "print(type(faces))\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw rectangles\n",
    "for x,y,w,h in faces:\n",
    "    img = cv2.rectangle(img1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "# resize image \n",
    "resize = cv2.resize(img, (int(img.shape[1]*2),int(img.shape[0]*2)) )\n",
    "\n",
    "cv2.imshow(\"a\",resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take image using video\n",
    "import time\n",
    "video = cv2.VideoCapture(0)\n",
    "check, frame = video.read()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "cv2.imshow(\"a\",frame) # show only first image of the video \n",
    "cv2.waitKey(0)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587\n"
     ]
    }
   ],
   "source": [
    "## take whole video\n",
    "video = cv2.VideoCapture(0)\n",
    "a=1\n",
    "while True:\n",
    "    a = a+1\n",
    "    check, frame = video.read()\n",
    "#     print(frame)\n",
    "    cv2.imshow(\"a\",frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "print(a)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection in the video\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.05, minNeighbors=5)\n",
    "    for x,y,w,h in faces:\n",
    "        img = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "    cv2.imshow(\"a\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
